{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcitQ-JNwD2g"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "GlW9CB7mwNJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_splits(base_folder, img_size=(299, 299)):\n",
        "    print(f\"üîç Loading datasets from: {base_folder}\")\n",
        "    splits = ['train', 'valid', 'test']\n",
        "    data = {}\n",
        "\n",
        "    for split in splits:\n",
        "        print(f\"\\nüìÇ Processing '{split}' split\")\n",
        "        folder = os.path.join(base_folder, split)\n",
        "        X, y, class_names = load_dataset(folder, img_size)\n",
        "        data[split] = (X, y)\n",
        "\n",
        "    return data, class_names\n"
      ],
      "metadata": {
        "id": "lXn84-x1wQKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_folder = r\"/content/drive/MyDrive/Gray mold iior/graymold\"\n",
        "data, class_names = load_all_splits(base_folder)\n"
      ],
      "metadata": {
        "id": "EbpU7V-SwSkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = data['train']\n",
        "X_valid, y_valid = data['valid']\n",
        "X_test, y_test = data['test']\n"
      ],
      "metadata": {
        "id": "9MWNgNMBwUeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_class_distribution(labels, class_names, title=\"Class Distribution\"):\n",
        "    counts = np.bincount(labels)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.barplot(x=class_names, y=counts)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"Image Count\")\n",
        "    plt.show()\n",
        "\n",
        "plot_class_distribution(y_train, class_names, title=\"Training Set Class Distribution\")\n"
      ],
      "metadata": {
        "id": "lYxnz_CCwWpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# ---------------- Force CPU ---------------- #\n",
        "tf.config.set_visible_devices([], 'GPU')\n",
        "print(\"‚úÖ Running on CPU only (MobileNetV2)\")\n",
        "\n",
        "# ---------------- Load Dataset ---------------- #\n",
        "# Make sure this is defined before running:\n",
        "# data, class_names = load_all_splits(base_folder, img_size=(224, 224))\n",
        "X_train, y_train = data['train']\n",
        "X_val, y_val = data['valid']\n",
        "\n",
        "# ---------------- Start Timing ---------------- #\n",
        "start_time = time.time()\n",
        "\n",
        "# ---------------- Define Model ---------------- #\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_mobilenet_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers[-20:]:  # Fine-tune fewer layers for MobileNetV2\n",
        "    layer.trainable = True\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "output_layer = Dense(len(class_names), activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ---------------- Train Model ---------------- #\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=8,  # MobileNetV2 is lightweight, so we can afford a larger batch\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ---------------- End Timing ---------------- #\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# ---------------- GPU / CPU Info ---------------- #\n",
        "def get_device_info():\n",
        "    try:\n",
        "        output = subprocess.check_output(\n",
        "            ['nvidia-smi', '--query-gpu=name,memory.used,memory.total,utilization.gpu,utilization.memory,power.draw', '--format=csv,noheader,nounits']\n",
        "        ).decode('utf-8').strip()\n",
        "        stats = output.split(',')\n",
        "        return {\n",
        "            'GPU Name': stats[0].strip(),\n",
        "            'Memory Used (MB)': f\"{stats[1].strip()} / {stats[2].strip()}\",\n",
        "            'GPU Load (%)': stats[3].strip(),\n",
        "            'Memory Load (%)': stats[4].strip(),\n",
        "            'Power Usage (W)': stats[5].strip()\n",
        "        }\n",
        "    except Exception:\n",
        "        return {\"Device\": \"Running on CPU or GPU not available\"}\n",
        "\n",
        "device_stats = get_device_info()\n",
        "\n",
        "# ---------------- Final Training Details ---------------- #\n",
        "final_epoch = len(history.history['accuracy'])\n",
        "final_acc = history.history['accuracy'][-1]\n",
        "final_loss = history.history['loss'][-1]\n",
        "\n",
        "print(\"\\nüìä Device Stats:\")\n",
        "for k, v in device_stats.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "print(\"\\nüèÅ Final Training Details:\")\n",
        "print(f\"  Total Epochs: {final_epoch}\")\n",
        "print(f\"  Final Loss: {final_loss:.4f}\")\n",
        "print(f\"  Final Accuracy: {final_acc:.4f}\")\n",
        "\n",
        "print(\"\\n‚è±Ô∏è Timing:\")\n",
        "print(f\"  CPU Time: {elapsed_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "VMd7ZpIawZIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "total_params = model.count_params()\n",
        "trainable_params = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
        "non_trainable_params = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
        "\n",
        "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "print(f\"Non-trainable Parameters: {non_trainable_params:,}\")"
      ],
      "metadata": {
        "id": "Si8vPtjby9ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_curves(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy', marker='o')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy', marker='o')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Accuracy over Epochs')\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss', marker='o')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss', marker='o')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Loss over Epochs')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call after training\n",
        "plot_training_curves(history)\n"
      ],
      "metadata": {
        "id": "bQhhZ6fIzTQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Predict\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "y_true = y_test  # <-- Fix here (remove argmax)\n",
        "\n",
        "# Accuracy\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"üß™ Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nüìÑ Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DYOKQp5uzFWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"üß© Confusion Matrix\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_test, y_pred, target_names=class_names, digits=3)\n",
        "print(\"üìã Classification Report:\\n\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "ANT-GpEozlj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üóÇÔ∏è Class Index Order Used in Training:\")\n",
        "for idx, name in enumerate(class_names):\n",
        "    print(f\"  {idx}: {name}\")\n"
      ],
      "metadata": {
        "id": "VdsDliPJz4dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Evaluate on Test Set ---------------- #\n",
        "X_test, y_test = data['test']\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"\\nüß™ Test Set Evaluation:\")\n",
        "print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "Ma34QXNxzatU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('PCM_mobv2.keras')"
      ],
      "metadata": {
        "id": "Vo3NlPa-z__r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}